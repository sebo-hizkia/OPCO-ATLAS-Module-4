# OPCO-ATLAS-Module-4-Brief-1

_M4 ‚Äì Brief 1 : Benchmark de mod√®les de r√©gression_

## üéØ Objectif

Construire et comparer plusieurs mod√®les de r√©gression pour pr√©dire le **prix m√©dian des logements** (en milliers de dollars) √† Boston, √† partir de donn√©es socio-√©conomiques et urbaines, en respectant :

- une **analyse √©thique** des variables,
- un **pipeline de pr√©paration** propre et reproductible,
- une **validation crois√©e** rigoureuse pour le benchmark.

---
## üìù Notebook

Pour ce projet j'ai utilis√© un Notebook pour consigner mon travail. Pour cela j'ai utilis√© JupyterLab.

````
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirement.txt
python3 -m ipykernel install --user
jupyter lab
````

Le Notebook est disponible dans ce d√©p√¥t : [Notebook](notebook.ipynb)
---

## üß© M√©thodologie

### 1. Chargement & exploration

- Chargement du dataset `bostonhousing.csv`.
- Inspection des dimensions, types de variables et statistiques descriptives.
- Visualisation des distributions pour chaque feature.
- V√©rification des valeurs manquantes (via `missingno`) : **aucune imputation n√©cessaire**.

---

### 2. Nettoyage & analyse √©thique

#### Variable supprim√©e

Dans la version finale du notebook, **une seule variable est retir√©e du jeu de donn√©es avant la mod√©lisation** :

| Variable | Description (classique Boston)                                           | D√©cision       | Raison principale |
|----------|---------------------------------------------------------------------------|----------------|-------------------|
| `b`      | Indice li√© √† la proportion de population afro-am√©ricaine dans le quartier | ‚ùå Supprim√©e    | Variable √©thiquement sensible, risque de discrimination dans un contexte d‚Äôaide √† la d√©cision publique ou priv√©e (urbanisme, cr√©dit, politique du logement). |

Cette suppression est un **choix √©thique conscient** : le mod√®le ne doit pas exploiter une information explicitement ou implicitement raciale pour pr√©dire des prix immobiliers.

---

### 3. Gestion des outliers

Les distributions √©tant souvent **asym√©triques**, une simple r√®gle IQR n‚Äôest pas adapt√©e partout.

J'ai donc mis en place une **fonction hybride** de d√©tection/traitement :

- configuration par variable (`summary`) indiquant la m√©thode √† appliquer :
  - `none` : aucune action,
  - `iqr_standard` : borne IQR classique,
  - `iqr_asymmetric` : borne IQR adapt√©e aux distributions asym√©triques,
  - `percentile` : capping par percentiles (ex. 1·µâ ≥‚Äì99·µâ).
- application d‚Äôun **capping (winsorisation)** sur les valeurs extr√™mes, au lieu de les supprimer.

R√©sultat : on **att√©nue l‚Äôinfluence des valeurs extr√™mes** sans perdre d‚Äôobservations.

---

### 4. Pr√©paration des donn√©es

Sur le dataset final (`df_final`) :

- S√©paration **features** / **cible** (`medv`).
- Identification des variables :
  - **num√©riques** (continues),
  - **cat√©gorielles** (si pr√©sentes).
- Construction d‚Äôun pipeline Scikit-learn combinant :
  - **StandardScaler** sur les variables continues,
  - **OneHotEncoder** sur les variables cat√©gorielles,
  - le mod√®le de r√©gression choisi.

Cette approche garantit :

- une **pr√©paration coh√©rente** pour tous les mod√®les,
- aucune fuite de donn√©es (fit uniquement sur le train).

---

## ü§ñ Mod√®les et validation

### Mod√®les test√©s

Le notebook compare les mod√®les suivants :

- `Linear Regression`
- `Ridge (alpha=1.0)`
- `Lasso (alpha=0.1)`
- `Decision Tree` (max_depth=5)
- `Random Forest` (100 arbres)
- `Gradient Boosting` (100 it√©rations)
- `K-Neighbors (k=5)`
- `SVR (rbf)`
- `XGBoost`
- `LightGBM`

### Sch√©ma d‚Äô√©valuation

- **Validation crois√©e 5-fold (KFold)** pour chaque mod√®le.
- M√©triques calcul√©es :
  - **R¬≤**
  - **RMSE**
  - **MAE**

Cela permet une **comparaison**, moins d√©pendante d‚Äôun simple split train/test.

---

## üìä R√©sultats principaux

D‚Äôapr√®s la cellule de synth√®se du notebook :

- ü•á **Meilleur mod√®le : Gradient Boosting**
  - **R¬≤ moyen ‚âà 0.8498**
  - **RMSE ‚âà 3.53** (en milliers de dollars)
- Les mod√®les ensemblistes (**Random Forest, Gradient Boosting, XGBoost, LightGBM**) **surclassent nettement** les mod√®les lin√©aires.
- **Gradient Boosting** et **XGBoost** pr√©sentent les **√©carts-types les plus faibles** en validation crois√©e ‚Üí bonne stabilit√©.
- Les mod√®les **lin√©aires** (Linear, Ridge, Lasso) restent corrects mais clairement en dessous des ensemblistes.
- **SVR (rbf)** est le **moins performant** dans ce benchmark.

---

## üõ†Ô∏è Choix techniques cl√©s

- Suppression de la variable **`b`** pour des raisons **√©thiques** (√©viter un mod√®le discriminatoire).
- Gestion des outliers par **strat√©gie hybride** configurable plut√¥t que r√®gle unique.
- **Standardisation** syst√©matique des variables continues (important pour les mod√®les √† r√©gularisation et SVR).
- **Encodage One-Hot** des variables cat√©gorielles.
- **Validation crois√©e 5-fold** pour une √©valuation robuste.
- Conservation d‚Äôune **baseline lin√©aire** pour mesurer les gains des mod√®les plus complexes.

---

## ‚úÖ Conclusion

- Le **Gradient Boosting** est retenu comme **mod√®le optimal** sur ce dataset, avec un **R¬≤ ‚âà 0.85** et un **RMSE ‚âà 3.53**, ce qui correspond √† une erreur moyenne d‚Äôenviron **3‚Äì4 milliers de dollars** sur la pr√©diction du prix m√©dian.
- Les **choix √©thiques** (notamment la suppression de `b`) et la **gestion fine des outliers** renforcent la cr√©dibilit√© du mod√®le dans un contexte d‚Äôusage r√©el.


